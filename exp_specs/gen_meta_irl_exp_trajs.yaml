# after running this you probably want to run normalize_meta_expert_demos.py on
# the demos to normalize them (use check meta expert replay buffer stats)
meta_data:
  script_path: run_scripts/gen_meta_irl_expert_trajs.py
  # exp_name: hc_rand_vel_expert_demos_0p125_spaced_tasks_64_demos_each_20_sub_det_policy
  # exp_name: stochastic_hc_rand_vel_expert_demos_0p125_separated_64_demos_per_task_20_sub_stoch_policy_3_layer_rew_4
  # exp_name: hc_rand_vel_expert_demos_0p125_separated_16_demos_per_task_20_sub_stoch_policy_3_layer_rew_4
  # exp_name: hc_rand_vel_very_good_expert_demos_0p1_separated_256_demos_per_task_no_subsample_correct_only_for_task_1
  # exp_name: hc_rand_vel_expert_demos_0p1_separated_4_demos_sub_20
  # exp_name: ant_agg_test_points_for_32_points_16_demos_sub_1
  # exp_name: ant_lin_class_64_tasks_16_demos_per_task_no_sub
  # exp_name: rel_pos_ant_lin_class_64_tasks_16_demos_per_task_no_sub
  # exp_name: walker_meta_dyn_32_det_demos_per_task_20_sub_fixed_save_problem_test_tasks

  # exp_name: check_ant_rand_direc_better_reward_1
  exp_name: check_ant_rand_goal_45_to_90
  description: generating expert demos for few shot
  use_gpu: true
  num_workers: 1
  cpu_range: [0,159]
  num_cpu_per_worker: 1
# -----------------------------------------------------------------------------
variables:
  use_scripted_policy: [false]
  render: [false]
  student_policy_uses_pixels: [false]
  # num_rollouts_per_task: [32]
  num_rollouts_per_task: [4]
  subsample_factor: [10]
  # subsample_factor: [20]
  # seed: [28043, 99381, 33478, 448293, 5739]
  seed: [28043]

# -----------------------------------------------------------------------------
constants:
  # the expert
  # 2 layer expert, rew 1
  # expert_dir: '/scratch/gobi2/kamyar/oorl_rlkit/output/meta-new-sac-halfcheetah-rand-vel-100-train-25-test/meta_new_sac_halfcheetah_rand_vel_100_train_25_test_2019_03_27_21_10_37_0000--s-0'
  # 3 layer expert, rew 1
  # expert_dir: '/scratch/gobi2/kamyar/oorl_rlkit/output/meta-new-sac-halfcheetah-rand-vel-100-train-25-test-3-layers-rew-1/meta_new_sac_halfcheetah_rand_vel_100_train_25_test_3_layers_rew_1_2019_04_05_02_45_58_0000--s-0/'
  # 3 layer expert, rew 4
  # expert_dir: '/scratch/gobi2/kamyar/oorl_rlkit/output/meta-new-sac-halfcheetah-rand-vel-100-train-25-test-3-layers-rew-4/meta_new_sac_halfcheetah_rand_vel_100_train_25_test_3_layers_rew_4_2019_04_05_02_49_51_0000--s-0/'
  # 2 layer expert, rew 80
  # expert_dir: /scratch/gobi2/kamyar/oorl_rlkit/output/meta-new-sac-halfcheetah-rand-vel-100-train-25-test/meta_new_sac_halfcheetah_rand_vel_100_train_25_test_2019_03_29_06_03_28_0015--s-0/
  # 3 layer expert, rew 4, no ctrl cost
  # expert_dir: /scratch/gobi2/kamyar/oorl_rlkit/output/no-ctrl-cost-meta-new-sac-halfcheetah-rand-vel-100-train-25-test-3-layers-rew-4/no_ctrl_cost_meta_new_sac_halfcheetah_rand_vel_100_train_25_test_3_layers_rew_4_2019_04_07_18_44_23_0000--s-0/

  # the expert we used for hc results in the paper
  # expert_dir: '/scratch/hdd001/home/kamyar/output/retry-hc-rand-vel-expert-rew-150/retry_hc_rand_vel_expert_rew_150_2019_04_13_11_36_46_0001--s-0'

  # ant agg five points expert
  # expert_dir: '/scratch/hdd001/home/kamyar/expert_demos/eight_points_ant_agg'
  # expert_dir: '/scratch/hdd001/home/kamyar/expert_demos/sixteen_points_train_and_test_ant_agg'
  # expert_dir: '/scratch/hdd001/home/kamyar/expert_demos/pi_over_32_16_points_test_ant_agg'

  # ant linear classification
  # expert_dir: '/scratch/hdd001/home/kamyar/expert_demos/ant_linear_classification_expert'

  # walker random dynamics
  # expert_dir: /scratch/hdd001/home/kamyar/expert_demos/walker_agg_dyn_expert_for_train_tasks
  # expert_dir: /scratch/hdd001/home/kamyar/expert_demos/walker_agg_dyn_expert_for_test_tasks

  # ant random direction
  # expert_dir: /scratch/hdd001/home/kamyar/output/ant-random-direction-running/ant_random_direction_running_2019_06_29_23_15_50_0004--s-0
  # expert_dir: /scratch/hdd001/home/kamyar/output/ant-random-direction-running-better-reward-function/ant_random_direction_running_better_reward_function_2019_06_30_19_12_11_0003--s-0
  # expert_dir: /scratch/hdd001/home/kamyar/output/ant-random-direction-running-better-reward-function/ant_random_direction_running_better_reward_function_2019_06_30_19_12_08_0000--s-0
  
  expert_dir: /scratch/hdd001/home/kamyar/output/ant-rand-goal-r-20-45-to-90/ant_rand_goal_r_20_45_to_90_2019_07_01_19_30_14_0000--s-0/

  env_specs:
    # base_env_name: 'halfcheetah_rand_vel'
    # base_env_name: 'halfcheetah_rand_vel_0p1_separated'
    # base_env_name: 'halfcheetah_rand_vel_debug_meta_sampelr'
    # base_env_name: 'halfcheetah_rand_vel_0p1_separated'
    # base_env_name: 'ant_rand_goal_five_points'
    # base_env_name: 'ant_rand_goal_two_points'
    # base_env_name: 'ant_rand_goal_opposite_2_directions'
    # base_env_name: 'ant_rand_goal_eight_points'
    # base_env_name: 'ant_rand_goal_sixteen_points_train_and_test'
    # base_env_name: 'ant_rand_goal_32_points'
    # base_env_name: 'ant_rand_goal_test_tasks_for_32_points'
    # base_env_name: 'ant_linear_classifier'
    # base_env_name: 'rel_pos_ant_linear_classifier'

    # base_env_name: 'walker_random_dynamics_train'
    # base_env_name: 'walker_random_dynamics_test'
    base_env_name: 'ant_rand_direc_running_45_to_135'

    normalized: false
    need_pixels: false

  # max_path_length: 100
  # max_path_length: 50
  # max_path_length: 1000
  max_path_length: 250
  wrap_absorbing: false
  no_terminal: false

  check_for_success: false

  policy_uses_pixels: false
  policy_uses_task_params: false
  concat_task_params_to_policy_obs: false
  
  get_deterministic_expert_demos: true

# 2 layer policy
# stochastic evaluation : -614.43 +/- 117.56
# determinisitc evaluation: -350.27 +/- 144.68

# 3 layer policy
# stochastic evaluation : -614.43 +/- 117.56
# determinisitc evaluation: -365.17 +/- 124.24

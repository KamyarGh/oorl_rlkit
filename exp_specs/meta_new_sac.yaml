meta_data:
  script_path: /h/kamyar/oorl_rlkit/run_scripts/sac.py
  exp_dirs: /scratch/gobi2/kamyar/oorl_rlkit/output/
  exp_name: ant_two_dir_no_norm_obs_rew_scale_200_path_300_actual_rew_scale_45_deg_farther
  # exp_name: custom_32_low_ctrl_cost_low_gear_ant_rand_goal_2_dir_rew_scale_5_roll_between_2_upd_200_batch_2_128_max_path_200
  description: searching over the SAC hyperparameters
  use_gpu: true
  num_workers: 2
  cpu_range: [0,159]
  num_cpu_per_worker: 2
# -----------------------------------------------------------------------------
variables:
  use_custom_ant_models: [true]
  goal_embed_dim: [32]
  algo_params:
    reward_scale: [200.0]
    # reward_scale: [1.0, 2.0, 5.0, 8.0, 10.0, 20.0, 40.0, 80.0]
    policy_uses_task_params: [true]
    policy_uses_pixels: [false]
  # seed: [1553]
  # seed: [1553, 7972, 9361, 1901]
  seed: [1553, 9361]

# -----------------------------------------------------------------------------
constants:
  algo_params:
    meta: true
    do_running_obs_norm: false

    num_epochs: 2001
    num_rollouts_per_epoch: 200
    num_rollouts_between_updates: 2
    num_initial_rollouts_for_all_train_tasks: 5
    num_tasks_per_eval: 2
    num_eval_trajs_per_task: 5
    num_updates_per_train_call: 300
    # max_path_length: 1000
    # max_path_length: 400
    # max_path_length: 200
    max_path_length: 300
    discount: 0.99
    replay_buffer_size_per_task: 500000
    # replay_buffer_size_per_task: 250000
    # replay_buffer_size_per_task: 10000
    # replay_buffer_size_per_task: 25000

    num_tasks_per_batch: 2
    num_samples_per_task_per_batch: 128
    soft_target_tau: 0.005

    policy_lr: 0.0003
    qf_lr: 0.0003
    vf_lr: 0.0003
    policy_mean_reg_weight: 0.001
    policy_std_reg_weight: 0.001

    render: false
    save_algorithm: true
    freq_saving: 5

  net_size: 256
  num_hidden_layers: 3

  env_specs:
    # base_env_name: 'ant_rand_goal_one_direction'
    base_env_name: 'ant_rand_goal_45_deg_farther'
    # base_env_name: 'ant_rand_goal_opposite_2_directions'
    # base_env_name: 'ant_rand_goal_2_directions'
    # base_env_name: 'ant_rand_goal_60_degrees'
    # base_env_name: 'ant_rand_goal_120_degrees'
    # base_env_name: 'ant_rand_goal_200_points'
    normalized: false
    train_test_env: false
    need_pixels: false

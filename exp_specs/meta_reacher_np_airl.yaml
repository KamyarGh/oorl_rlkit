meta_data:
  script_path: /u/kamyar/oorl_rlkit/run_scripts/train_np_airl.py
  exp_dirs: /ais/gobi6/kamyar/oorl_rlkit/output
  exp_name: meta_simple_meta_reacher_np_airl_hype_search
  description: searching over the SAC hyperparameters
  use_gpu: false
  num_workers: 24
  cpu_range: [0,25]
  num_cpu_per_worker: 1
# -----------------------------------------------------------------------------
variables:

  algo_params:
    policy_params:
      reward_scale: [1.0, 5.0, 10.0, 25.0, 50.0, 100.0]
    
    disc_net_size: [100, 256]

  # seed: [9783]
  # seed: [9783, 5914, 4865, 2135, 2349]
  seed: [9783, 5914]

# -----------------------------------------------------------------------------
constants:
  expert_name: meta_simple_meta_reacher_expert_no_subsampling_50_trajs_per_task
  expert_seed_run_idx: 0

  algo_params:
    num_epochs: 502
    num_rollouts_per_epoch: 16
    min_rollouts_before_training: 0
    max_path_length: 100

    replay_buffer_size_per_task: 100000
    no_terminal: false

    num_policy_updates_per_epoch: 100
    num_disc_updates_per_epoch: 100
    num_tasks_used_per_update: 16
    num_context_trajs_for_training: 3
    test_batch_size_per_task: 32

    num_tasks_per_eval: 16
    num_diff_context_per_eval_task: 2
    num_context_trajs_for_eval_task: 3
    num_eval_trajs_per_post_sample: 2

    num_context_trajs_for_exploration: 3

    # policy params
    policy_net_size: 256
    policy_uses_pixels: false
    policy_params:
      # policy always has 2 hidden layers
      # reward_scale: 1.0
      discount: 0.99
      policy_lr: 0.0003
      qf_lr: 0.0003
      vf_lr: 0.0003
      policy_mean_reg_weight: 0.001
      policy_std_reg_weight: 0.001
      soft_target_tau: 0.005
    
    encoder_lr: 0.0003
    disc_lr: 0.0003

    use_grad_pen: true
    grad_pen_weight: 10.0
    
    np_params:
      z_dim: 20

      traj_enc_params:
        timestep_enc_params:
          # input_size must be inferred based on env
          hidden_sizes: [50]
          output_size: 50

        traj_enc_params:
          # input_size must be inferred
          hidden_sizes: [100]
          output_size: 100
      
      r2z_map_params:
        trunk_params:
          # input_size must be inferred
          hidden_sizes: []
          output_size: 100
        split_heads_params:
          # input_size must be inferred
          hidden_sizes: [100]
          # output_size must be inferred
      
      np_enc_params:
        agg_type: 'sum'
        

    save_replay_buffer: true
    save_algorithm: true
    render: false

    freq_saving: 50
    
  env_specs:
    base_env_name: 'meta_simple_meta_reacher'
    normalized: false

meta_data:
  script_path: /u/kamyar/oorl_rlkit/run_scripts/dqn.py
  exp_dirs: /u/kamyar/oorl_rlkit/output
  exp_name: debug_meta_dqn
  description: searching over the DQN hyperparameters
  num_workers: 1
  cpu_range: [24,25]
  num_cpu_per_worker: 1

# -----------------------------------------------------------------------------
variables:
  algo_params:
    epoch_to_start_training: [10]
    num_updates_per_env_step: [1]
    # num_updates_per_env_step: [1, 4]
    learning_rate: [0.001]
    # learning_rate: [0.001, 0.0003]
    # tau: [0.005]
    # tau: [0.001, 0.005]
    max_path_length: [50]
    # max_path_length: [50, 100]
  
  env_specs:
    timestep_cost: [0.1]
  
  # seed: [9783, 5914, 4865, 2135, 2349]
  seed: [9783]

# -----------------------------------------------------------------------------
constants:
  algo_params:
    animated_eval: true
    num_epochs: 51
    num_steps_per_epoch: 1000
    num_steps_per_eval: 1000
    batch_size: 128
    discount: 0.99

    epsilon: 0.1
    tau: 0.001
    # hard_update_period: 1000

    render: false

    save_replay_buffer: true


  conv_input: false
  net_size: 256
  num_layers: 3

  # conv_input: true
  # kernel_sizes: [3, 3]
  # num_channels: [32, 32]
  # strides: [1, 1]
  # paddings: [1, 1]
  # hidden_sizes: [128, 128]


  env_specs:
    base_env_name: 'meta_maze'

    add_noise: true
    noise_scale: 0.1

    flat_repr: true
    one_hot_repr: true
    num_object_types: 1
    num_per_object: 10
    maze_h: 5
    maze_w: 5
    possible_reward_values: [1]
    shuffle: false
    scale: 1

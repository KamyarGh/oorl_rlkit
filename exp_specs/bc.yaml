meta_data:
  script_path: /h/kamyar/oorl_rlkit/run_scripts/bc_train_script.py
  exp_dirs: /scratch/gobi2/kamyar/oorl_rlkit/output
  # exp_name: tanh_gauss_no_reg_no_norm_log_prob_halfcheetah_25_demos_subsample_20
  # exp_name: finally_totally_absolute_final_bc_on_varying_data_amounts
  # exp_name: normalized_finally_totally_absolute_final_bc_on_varying_data_amounts
  # exp_name: test_rev_KL_bc
  # exp_name: ant_correct_normalized_forw_and_rev_KL_bc
  exp_name: what_matters_halfcheetah_BC_model_256
  description: searching over the SAC hyperparameters
  use_gpu: false
  num_workers: 14
  cpu_range: [0,159]
  num_cpu_per_worker: 1
# -----------------------------------------------------------------------------
variables:
  policy_net_size: [256]
  policy_num_hidden_layers: [2]
  policy_uses_bn: [false]
  policy_uses_layer_norm: [false]

  scale_env_with_given_demo_stats: [true]

  algo_params:
    save_best: [true]
    save_best_starting_from_epoch: [0]
    
    rev_KL: [false]
    expert_path: [/scratch/gobi2/kamyar/oorl_rlkit/expert_demos/HC_expert_policy/expert.pkl]
    # expert_path: [/scratch/gobi2/kamyar/oorl_rlkit/expert_demos/Ant_expert_policy/expert.pkl]

    no_terminal: [true]
    replay_buffer_size: [20000]

    num_update_loops_per_train_call: [1000]
    num_policy_updates_per_loop_iter: [1]

    optim_batch_size: [256]
    policy_lr: [0.0003]
    # policy_lr: [0.0003, 0.001]
  
  env_specs:
    normalized: [false]
  
  # seed: [9783, 5914, 4865, 2135, 2349]
  expert_seed_run_idx: [0]
  seed: [9783, 5914]
  # seed: [9783, 5914, 4865]

  expert_name: [
    # halfcheetah_256_demos_20_subsampling,
    # halfcheetah_128_demos_20_subsampling,
    # halfcheetah_64_demos_20_subsampling,
    # halfcheetah_32_demos_20_subsampling,
    # halfcheetah_16_demos_20_subsampling,
    # halfcheetah_8_demos_20_subsampling,
    # halfcheetah_4_demos_20_subsampling,

    norm_halfcheetah_256_demos_20_subsampling,
    norm_halfcheetah_128_demos_20_subsampling,
    norm_halfcheetah_64_demos_20_subsampling,
    norm_halfcheetah_32_demos_20_subsampling,
    norm_halfcheetah_16_demos_20_subsampling,
    norm_halfcheetah_8_demos_20_subsampling,
    norm_halfcheetah_4_demos_20_subsampling,
    # # normalized_halfcheetah_250_demos_no_subsampling,

    # norm_ant_256_demos_20_subsampling,
    # norm_ant_128_demos_20_subsampling,
    # norm_ant_64_demos_20_subsampling,
    # norm_ant_32_demos_20_subsampling,
    # norm_ant_16_demos_20_subsampling,
    # norm_ant_8_demos_20_subsampling,
    # norm_ant_4_demos_20_subsampling,
  ]

# -----------------------------------------------------------------------------
constants:
  # expert_name: halfcheetah_250_demos_no_subsampling
  # expert_name: halfcheetah_25_demos_subsample_20
  wrap_absorbing_state: false

  algo_params:
    num_epochs: 201
    num_steps_per_epoch: 1000
    num_steps_per_eval: 10000
    num_steps_between_updates: 1000
    max_path_length: 1000
    min_steps_before_training: 0

    policy_uses_task_params: false
    concat_task_params_to_policy_obs: false
    policy_uses_pixels: false

    policy_mean_reg_weight: 0.0
    policy_std_reg_weight: 0.0
    # policy_mean_reg_weight: 0.001
    # policy_std_reg_weight: 0.001
    
    save_replay_buffer: false
    render: false

    freq_saving: 20
    
  env_specs:
    # base_env_name: 'ant_v2'
    base_env_name: 'halfcheetah_v2'
    train_test_env: false

- using AIRL/DAC style max-ent IRL to do natural language generative models
- it's ridiculously hard, can we somehow combine IRL with a sparse reward or desired goal example?
- hierarchical (maybe even multi-level) but you have a discriminator for each level and the encoder that processes trajs
    is the same for both policy and expert trajs
- model-based RL using energy based models that takes into account the future states the model will be forced to predict in
- discrete has little information flow even with gumbel softmax but maybe you can have continuous mixture of Gaussians
    and throughout training try to separate the mixtures from each other as far as possible and shrink them to become
    discrete. Or maybe a better way is to somehow incorporate a hopfield type of architecture. Then maybe we can
    do really good hierarchical BC or IRL without needing to make all those assumptions like Poisson or even
    how many there are etc.
- learning mutually independent functions, i.e. mutually independent {(x,y)} sets so that if you know how one function
    looks like you don't know anything about the other functions. This could be useful for model-based RL. In that
    case wanna have mutually independent {(s,a,s')} so maybe you want to cluster actions, or cluster action dimensions????
- learning from demonstrations plus reward (maybe sparse) and treat the problem as annealed importance sampling
